# -*- coding: utf-8 -*-
"""Trabalho_I2DL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JaxqXjWMOqKyRjSS4lgHy0GTfFwAokiF
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import time
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import time
# Modelos
from torchvision.models import (
    resnet50, ResNet50_Weights,
    efficientnet_b0, EfficientNet_B0_Weights,
    efficientnet_b1, EfficientNet_B1_Weights,
    efficientnet_b2, EfficientNet_B2_Weights,
    efficientnet_b3, EfficientNet_B3_Weights
)

"""**CONFIGURAÇÕES**

"""

model_name = "efficientnet_b3"  # Opções: "resnet50", "efficientnet_b0", "efficientnet_b1", "efficientnet_b2" e "efficientnet_b3"

data_dir = '/content/drive/MyDrive/teste_autismo/AutismDataset'
model_save_dir = '/content/drive/MyDrive/teste_autismo/trained_models_unificado'
batch_size = 64
image_size = (248, 248)
num_classes = 2
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
os.makedirs(model_save_dir, exist_ok=True)

"""**TRANSFORMAÇÕES**"""

train_transform = transforms.Compose([
    transforms.Resize(image_size),
    transforms.RandomHorizontalFlip(),  # augmentation só no treino
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

eval_transform = transforms.Compose([
    transforms.Resize(image_size),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

"""**CARREGAMENTO DOS DADOS**"""

train_dataset = datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=train_transform)
val_dataset   = datasets.ImageFolder(os.path.join(data_dir, 'valid'), transform=eval_transform)
test_dataset  = datasets.ImageFolder(os.path.join(data_dir, 'test'), transform=eval_transform)

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

"""**MODELO**"""

if model_name == "resnet50":
    model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)
    for param in model.parameters():
        param.requires_grad = False
    model.fc = nn.Linear(model.fc.in_features, num_classes)

elif model_name == "efficientnet_b0":
    model = efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)
    for param in model.parameters():
        param.requires_grad = False
    model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)

elif model_name == "efficientnet_b1":
    model = efficientnet_b1(weights=EfficientNet_B1_Weights.IMAGENET1K_V2)
    for param in model.parameters():
        param.requires_grad = False
    model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)

elif model_name == "efficientnet_b2":
    model = efficientnet_b2(weights=EfficientNet_B2_Weights.IMAGENET1K_V1)
    for param in model.parameters():
        param.requires_grad = False
    model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)

elif model_name == "efficientnet_b3":
    model = efficientnet_b3(weights=EfficientNet_B3_Weights.IMAGENET1K_V1)
    for param in model.parameters():
        param.requires_grad = False
    model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)

else:
    raise ValueError("Modelo não suportado. Escolha 'resnet50' ou 'efficientnet_b0'.")

model = model.to(device)
criterion = nn.CrossEntropyLoss()

"""**FUNÇÃO DE AVALIAÇÃO**"""

def evaluate(model, data_loader, criterion, dataset_name):
    model.eval()
    loss = 0.0
    all_preds, all_labels = [], []
    with torch.no_grad():
        for inputs, labels in data_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss += criterion(outputs, labels).item() * inputs.size(0)
            _, preds = torch.max(outputs, 1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
    loss /= len(data_loader.dataset)
    acc = accuracy_score(all_labels, all_preds)
    prec = precision_score(all_labels, all_preds)
    rec = recall_score(all_labels, all_preds)
    f1 = f1_score(all_labels, all_preds)
    print(f"{dataset_name} — Loss: {loss:.4f} | Acc: {acc:.4f} | Prec: {prec:.4f} | Recall: {rec:.4f} | F1: {f1:.4f}")
    return acc


start_time = time.time()

"""**FASE 1 — CONFIGURAÇÃO 1**"""

print(f"\nTreinando {model_name.upper()} — FASE 1: Última camada (5 épocas)")
if model_name == "resnet50":
    optimizer = optim.Adam(model.fc.parameters(), lr=0.001)
else:
    optimizer = optim.Adam(model.classifier[1].parameters(), lr=0.001)

for epoch in range(5):
    model.train()
    train_loss, all_train_preds, all_train_labels = 0.0, [], []
    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        train_loss += loss.item() * inputs.size(0)
        _, preds = torch.max(outputs, 1)
        all_train_preds.extend(preds.cpu().numpy())
        all_train_labels.extend(labels.cpu().numpy())
    train_loss /= len(train_loader.dataset)
    print(f"Epoch {epoch+1}/5 — Loss Treino: {train_loss:.4f} | Acc: {accuracy_score(all_train_labels, all_train_preds):.4f}")
    evaluate(model, val_loader, criterion, "Validação")
torch.save(model.state_dict(), os.path.join(model_save_dir, f"{model_name}_phase1.pth"))

"""**FASE 2 — CONFIGURAÇÃO 2**"""

print("\nFASE 2: Liberando todas as camadas exceto as duas últimas (7 épocas)")

# Descongela tudo
for param in model.parameters():
    param.requires_grad = True

# Congela as duas últimas camadas
if model_name == "resnet50":
    for param in model.layer3.parameters():
        param.requires_grad = False
    for param in model.layer4.parameters():
        param.requires_grad = False
elif model_name == "efficientnet_b0" or "efficientnet_b1" or "efficientnet_b2" or "efficientnet_b3" :
    for param in model.features[7].parameters():
        param.requires_grad = False
    for param in model.features[8].parameters():
        param.requires_grad = False

# Otimizador só para o que está liberado
optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)


for epoch in range(7):
    model.train()
    train_loss, all_train_preds, all_train_labels = 0.0, [], []
    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        train_loss += loss.item() * inputs.size(0)
        _, preds = torch.max(outputs, 1)
        all_train_preds.extend(preds.cpu().numpy())
        all_train_labels.extend(labels.cpu().numpy())
    train_loss /= len(train_loader.dataset)
    print(f"Epoch {epoch+1}/7 — Loss Treino: {train_loss:.4f} | Acc: {accuracy_score(all_train_labels, all_train_preds):.4f}")
    evaluate(model, val_loader, criterion, "Validação")
torch.save(model.state_dict(), os.path.join(model_save_dir, f"{model_name}_phase2.pth"))

"""**FASE 3 — CONFIGURAÇÃO 3**"""

print("\nFASE 3: Fine-tuning total (8 épocas)")
for param in model.parameters():
    param.requires_grad = True

optimizer = optim.Adam(model.parameters(), lr=1e-5)
for epoch in range(8):
    model.train()
    train_loss, all_train_preds, all_train_labels = 0.0, [], []
    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        train_loss += loss.item() * inputs.size(0)
        _, preds = torch.max(outputs, 1)
        all_train_preds.extend(preds.cpu().numpy())
        all_train_labels.extend(labels.cpu().numpy())
    train_loss /= len(train_loader.dataset)
    print(f"Epoch {epoch+1}/8 — Loss Treino: {train_loss:.4f} | Acc: {accuracy_score(all_train_labels, all_train_preds):.4f}")
    evaluate(model, val_loader, criterion, "Validação")
torch.save(model.state_dict(), os.path.join(model_save_dir, f"{model_name}_phase3.pth"))

"""**AVALIAÇÃO FINAL**"""

print("\nAvaliação final no conjunto de teste")
evaluate(model, test_loader, criterion, "Teste")
end_time = time.time()
print(f"Tempo: {end_time - start_time:.2f} segundos")